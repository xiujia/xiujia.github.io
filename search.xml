<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python进程线程 - threading]]></title>
    <url>%2F2018%2F01%2F18%2Fthreading%2F</url>
    <content type="text"><![CDATA[python线程简介可以用线程来执行阻塞式I/O,但不要用它做平行计算 标准的Python实现叫做CPython。Cpython分两步来运行Python程序： 首先，把文本形式的源代码解析并编译成字节码 然后，用一种基于栈的解释器来运行这份字节码 执行Python程序时，字节码解释器必须保持协调一致的状态。Python采用GIL(global inerpreter lock,全局解释器锁)机制来确保这种协调性(coherence)。 GIL实际上就是一把互斥锁(mutual-exclusion-lock,又称为mutex)，用以防止CPython受到占先式多线程切换(preemptive multithreaing)操作的干扰。 GIL有一种非常显著额负面影响。用C++或者Java等语言写程序时，可以同时执行多条线程，以充分利用计算机所配备的多个CPU核心。Python程序尽管也支持多线程，但由于受到GIL保护，所以同一时刻，只有一条线程可以向前执行。这就意味着，如果我们想利用多线程做平行计算(parallel computation)， 并希望借此为Python程序提速，那么结果会非常令人失望。 既然如此，Python为什么还要支持多线程呢？ 首先，多线程使得到程序看上去好像能够在同一时间做许多事情。如果要自己实现这种效果，并手工管理任务之间的切换，那就显得比较困难 其次，在处理阻塞式I/O时很有用。读写文件、在网络间通信，以及与显示器等设备相交互等，都属于阻塞式的I/O操作。为了响应这种阻塞式的请求，操作系统必须花一些时间，而开发者可以借助多线程，把python程序与这些耗时的I/O操作隔离开。(python在执行系统调用的时候会释放GIL)。当然除了线程，还有一些其他的方，也能处理阻塞式的I/O操作，例如内置的asyncio模块等。相对于这些模块，使用多线程来实现会比较简单一些。 使用线程threading.ThreadThread 是threading模块中最重要的类之一，可以使用它来创建线程。有两种方式来创建线程： 一种是创建一个threading.Thread对象，在它的初始化函数（init）中将可调用对象作为参数传入。 另一种是通过继承Thread类，重写它的run方法； 下面分别举例说明：开启4个线程，每个线程进行10次+1操作 先来看看通过创建继承threading.Thread对象来创建线程的例子： 123456789101112131415161718192021222324252627import timeimport randomimport threadingdef func1(loop): """创建threading.Thread对象的方式创建线程""" global func1_count, func1_lock thread_name = threading.currentThread().getName() # 获取线程名 for _ in range(loop): with func1_lock: func1_count += 1 print(thread_name, func1_count) time.sleep(1)def func1_main(num): global func1_count, func1_lock threads = [] func1_count = 0 func1_lock = threading.Lock() # 线程中使用Lock防止数据竞争 for i in range(num): t = threading.Thread(target=func1,args=(10, )) threads.append(t) for t in threads: t.start() # 启动所有线程 for t in threads: t.join() # 主线程中等待所有子线程退出 继承Thread类: 1234567891011121314151617181920212223242526class Counter(threading.Thread): my_count = 0 # 类变量 my_lock = threading.Lock() def __init__(self, loop=10): super().__init__() self._loop = loop # self._count = init_count # self._lock = threading.Lock() def run(self): thread_name = threading.currentThread().getName() for _ in range(self._loop): with Counter.my_lock: Counter.my_count += 1 print(thread_name, Counter.my_count) time.sleep(1)def func2_main(num): threads = [] for _ in range(num): t = Counter() # 默认loop为10，init_count为0 t.start() threads.append(t) for t in threads: t.join() 相对于方法一的修改，不使用global而是使用一个自定义的counter类 12345678910111213141516171819202122232425class LockingCounter(object): def __init__(self, init_count): self._lock = threading.Lock() self._count = init_count def increase(self, offset=1): with self._lock: self._count += 1def worker(index, loop, counter): thread_name = threading.currentThread().getName() for _ in range(loop): counter.increase(1) print(thread_name, counter._count) time.sleep(1)def func3_main(num, func, loop, counter): threads = [] for i in range(num): args = (i, loop, counter) t = threading.Thread(target=func, args=args) threads.append(t) t.start() for t in threads: t.join() 运行： 123456789if __name__ == '__main__': print('-----method1-----:') thread_num = 4 func1_main(thread_num) print('-----method2-----:') func2_main(thread_num) print('-----method3-----:') counter = LockingCounter(0) func3_main(thread_num, worker, 10, counter) 使用Queue来协调各线程之间的工作管线(Pipeline)是一种优秀的任务处理方式，它可以把处理流程分为若干阶段，并使用多条Python线程来同时执行这些任务 构建并发式的管线时，要注意许多问题，其中包括：如何防止某个阶段陷入持续等待的状态之中、如何停止工作线程，以及如何防止内存膨胀等。 Queue类所提供的的机制，可以彻底解决上述问题，它具备阻塞式的队列操作、能够制定缓冲区尺寸，而且还支持join方法，这使得开发者可以构建出健壮的管线。 示例：生产者消费者模型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import timeimport randomimport threadingfrom queue import Queue # 队列模块from itertools import chainq = Queue()sentinel = object() # 结束标记def Producer(nums): """生产者函数 nums:product起始编号元组,例如(1,10)""" thread_name = threading.currentThread().getName() for item in range(*nums): q.put(item) print('[+] %s 生产 item%s' % (thread_name,item)) time.sleep(random.randrange(2)) # 控制生产速度def Consumer(): """消费者函数""" thread_name = threading.currentThread().getName() while True: data = q.get() if data is sentinel: print('[x] %s 退出' % thread_name) break print('[-] %s 消费 item%s' % (thread_name, data)) time.sleep(1)def run(): """主函数""" pnum = 2 cnum = 3 # 生产者线程，每个线程生产10个，1号线程生产1，10，2号生产11-20...... pthreads = [ threading.Thread(target=Producer, args=((i * 10 + 1, (i + 1) * 10 + 1),), name="生产者%d号" % (i + 1)) for i in range(pnum)] # 消费者线程 cthreads = [ threading.Thread(target=Consumer, name="消费者%d号" % (i + 1)) for i in range(cnum)] for thread in chain(pthreads, cthreads): thread.start() for pt in pthreads: pt.join() # 生产线程阻塞 for _ in range(cnum): q.put(sentinel) # put结束标记 for ct in cthreads: ct.join() print("all done")if __name__ == '__main__': run() output: 123456789101112......[+] 生产者1号 生产 item8[-] 消费者2号 消费 item8[+] 生产者1号 生产 item9[-] 消费者3号 消费 item9[+] 生产者1号 生产 item10[-] 消费者2号 消费 item10[x] 消费者1号 退出[x] 消费者3号 退出[x] 消费者2号 退出all done 管线 我们构建一个有三个阶段的管线：下载图片–&gt;&gt;调整大小–&gt;&gt;重新上传 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# -*- coding: utf-8 -*-"""用threading模块和Queue实现管线"""import timeimport threadingfrom queue import Queueclass ClosableQueue(Queue): """带有终止信号的Queue close时put终止信号""" SENTINEL = object() # 终止信号 def close(self): self.put(self.SENTINEL) def __iter__(self): while True: item = self.get() try: if item is self.SENTINEL: return # 致使线程退出 yield item finally: self.task_done()class StopableWorker(threading.Thread): """queue遇到终止信号的线程退出""" def __init__(self, func, in_queue, out_queue): super().__init__() self.func = func self.in_queue = in_queue self.out_queue = out_queue def run(self): for item in self.in_queue: result = self.func(item) if result is not None: self.out_queue.put(result)def download(item): """下载""" print('download item ', item) time.sleep(0.1) return item def resize(item): """调整""" print('resize item ', item) time.sleep(0.1) return itemdef upload(item): """上传""" print('upload item ', item) return item def main(): """主程序""" # 各阶段队列 download_queue = ClosableQueue() resize_queue = ClosableQueue() upload_queue = ClosableQueue() out_queue = Queue() # 线程 threads = [ StopableWorker(download, download_queue, resize_queue), StopableWorker(resize, resize_queue, upload_queue), StopableWorker(upload, upload_queue, out_queue) ] for thread in threads: thread.start() for i in range(1, 101): download_queue.put(i) download_queue.close() download_queue.join() resize_queue.close() resize_queue.join() upload_queue.close() upload_queue.join() print(out_queue.qsize(), 'pictures finished') # while not out_queue.empty(): # print(out_queue.get())if __name__ == '__main__': main() output: 1234567891011121314......upload item 96resize item 97upload item 97resize item 98download item 99download item 100resize item 99upload item 98upload item 99resize item 100upload item 100100 pictures finished]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>Queue</tag>
        <tag>Producer_Consumer</tag>
        <tag>Pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python进程线程 - subprocess]]></title>
    <url>%2F2018%2F01%2F18%2Fsubprocess%2F</url>
    <content type="text"><![CDATA[subprocess模块是python从2.4版本开始引入的模块。主要用来取代 一些旧的模块方法，如os.system、os.spawn、os.popen、commands等。subprocess通过子进程来执行外部指令，并通过input/output/error管道，获取子进程的执行的返回信息。 常用方法subprocess.call()执行命令，并返回执行状态，其中shell参数为False时，命令需要通过列表的方式传入，当shell为True时，可直接传入命令 1234567891011121314151617181920&gt;&gt;&gt; import subprocess&gt;&gt;&gt; child = subprocess.call(['df', '-h'], shell=False)Filesystem Size Used Avail Use% Mounted onudev 475M 0 475M 0% /devtmpfs 99M 2.9M 97M 3% /run/dev/vda1 40G 9.5G 28G 26% /tmpfs 495M 4.0K 495M 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 495M 0 495M 0% /sys/fs/cgrouptmpfs 99M 0 99M 0% /run/user/1000&gt;&gt;&gt; child2 = subprocess.call('df -h', shell=True)Filesystem Size Used Avail Use% Mounted onudev 475M 0 475M 0% /devtmpfs 99M 2.9M 97M 3% /run/dev/vda1 40G 9.5G 28G 26% /tmpfs 495M 4.0K 495M 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 495M 0 495M 0% /sys/fs/cgrouptmpfs 99M 0 99M 0% /run/user/1000 subprocess.check_call()用法与subprocess.call()类似，区别是，当返回值不为0时，直接抛出异常 123456789101112131415161718&gt;&gt;&gt; child3 = subprocess.check_call('df -h', shell=True)Filesystem Size Used Avail Use% Mounted onudev 475M 0 475M 0% /devtmpfs 99M 2.9M 97M 3% /run/dev/vda1 40G 9.5G 28G 26% /tmpfs 495M 4.0K 495M 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 495M 0 495M 0% /sys/fs/cgrouptmpfs 99M 0 99M 0% /run/user/1000&gt;&gt;&gt; print(child3)0&gt;&gt;&gt; child4 = subprocess.check_call('df-h', shell=True)/bin/sh: 1: df-h: not foundTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/cg/anaconda3/lib/python3.6/subprocess.py", line 291, in check_call raise CalledProcessError(retcode, cmd)subprocess.CalledProcessError: Command 'df-h' returned non-zero exit status 127. subprocess.check_output()用法与上面两个方法类似，区别是，如果当返回值为0时，不直接输出结果，如果返回值不为0，直接抛出异常。需要说明的是，该方法在python3.x中才有。 123&gt;&gt;&gt; child5 = subprocess.check_output('df -h', shell=True)&gt;&gt;&gt; child5b'Filesystem Size Used Avail Use% Mounted on\nudev 475M 0 475M 0% /dev\ntmpfs 99M 2.9M 97M 3% /run\n/dev/vda1 40G 9.5G 28G 26% /\ntmpfs 495M 4.0K 495M 1% /dev/shm\ntmpfs 5.0M 4.0K 5.0M 1% /run/lock\ntmpfs 495M 0 495M 0% /sys/fs/cgroup\ntmpfs 99M 0 99M 0% /run/user/1000\n' subprocess.Popen()在一些复杂场景中，我们需要将一个进程的执行输出作为另一个进程的输入。在另一些场景中，我们需要先进入到某个输入环境，然后再执行一系列的指令等。这个时候我们就需要使用到suprocess的Popen()方法。该方法有以下参数： args：shell命令，可以是字符串，或者序列类型，如list,tuple。 bufsize：缓冲区大小，可不用关心 stdin,stdout,stderr：分别表示程序的标准输入，标准输出及标准错误 shell：与上面方法中用法相同 cwd：用于设置子进程的当前目录 env：用于指定子进程的环境变量。如果env=None，则默认从父进程继承环境变量 universal_newlines：不同系统的的换行符不同，当该参数设定为true时，则表示使用\n作为换行符 示例1：在~/test下创建一个suprocesstest的目录， 以及删除： 1234&gt;&gt;&gt; child6 = subprocess.Popen('mkdir subprocesstest',shell=True,cwd='/home/cg/test')# 查看目录，已经创建该文件夹&gt;&gt;&gt; child7 = subprocess.Popen('rmdir subprocesstest',shell=True,cwd='/home/cg/test')# 查看目录，已经删除该文件夹 示例2: 使用python执行几个命令 12345678910111213141516import subprocessproc = subprocess.Popen(["python"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)proc.stdin.write('print(1)\n'.encode('utf-8'))proc.stdin.write('print(2)\n'.encode('utf-8'))proc.stdin.write('print(3)\n'.encode('utf-8'))proc.stdin.close()cmd_out = proc.stdout.read()proc.stdout.close()cmd_error = proc.stderr.read()proc.stderr.close()print(cmd_out)print(cmd_error) output: 12b'1\n2\n3\n'b'' 或者使用communicate()方法： 12345678910import subprocessproc = subprocess.Popen(["python"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)proc.stdin.write('print(1)\n'.encode('utf-8'))proc.stdin.write('print(2)\n'.encode('utf-8'))proc.stdin.write('print(3)\n'.encode('utf-8'))out_err_list = proc.communicate()print(out_err_list) output: 1(b'1\n2\n3\n', b'') #(out,err)元组 示例3: 将一个子进程的输出，作为另一个子进程的输入 12345# 类似于shell的cat /etc/passwd | grep 0:0import subprocesschild1 = subprocess.Popen(["cat","/etc/passwd"], stdout=subprocess.PIPE)child2 = subprocess.Popen(["grep","0:0"],stdin=child1.stdout, stdout=subprocess.PIPE)out = child2.communicate() 其他方法： 123456import subprocesschild = subprocess.Popen('sleep 60',shell=True,stdout=subprocess.PIPE)child.poll() #检查子进程状态child.kill() #终止子进程child.send_signal() #向子进程发送信号child.terminate() #终止子进程]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>subprocess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github + hexo + Next 搭建免费个人博客]]></title>
    <url>%2F2018%2F01%2F12%2Fdeploy-hexo-next%2F</url>
    <content type="text"></content>
      <categories>
        <category>技术随笔</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F01%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
</search>
